{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Neural Network with MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images,mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(object):\n",
    "    \n",
    "    def __init__(self, sizes, X, Y, epoches=5, applyPCA=False):\n",
    "        # Hyperparameters\n",
    "        self._sizes = sizes\n",
    "        self._X = X\n",
    "        self._Y = Y\n",
    "        self._learning_rate =  1.0\n",
    "        self._momentum = 0.0\n",
    "        self._epoches = epoches\n",
    "        self._batchsize = 100\n",
    "        self.input_size = X.shape[1]\n",
    "        self.output_size = Y.shape[1]\n",
    "        self.w_tf_list = []\n",
    "        self.b_tf_list = []\n",
    "        \n",
    "        # Weights and Biases\n",
    "        tf.reset_default_graph() # reset tensorflow graph\n",
    "        with tf.variable_scope(\"FC\"):            \n",
    "            pre_size = self.input_size\n",
    "            for i, size in enumerate(self._sizes + [Y.shape[1]]):\n",
    "                self.w_tf_list.append(tf.get_variable(str('w'+str(i+1)), shape=[pre_size, size], dtype=tf.float32))\n",
    "                # initialize biases\n",
    "                self.b_tf_list.append(tf.get_variable(str('b'+str(i+1)), shape=[size], dtype=tf.float32))\n",
    "                pre_size = size\n",
    "    \n",
    "    def train(self):\n",
    "        # Placeholders\n",
    "        Xph = tf.placeholder(\"float\", [None, self.input_size])\n",
    "        Yph = tf.placeholder(\"float\", [None, self.output_size])\n",
    "        \n",
    "        ##LAYERs\n",
    "        layers_list = []\n",
    "        pre_layer_out = Xph\n",
    "        for i, size in enumerate(self._sizes):\n",
    "            layers_list.append(tf.nn.sigmoid(tf.matmul(pre_layer_out, self.w_tf_list[i]) + self.b_tf_list[i]))\n",
    "            pre_layer_out = layers_list[-1]\n",
    "        # Output Layer\n",
    "        Y_hat = tf.nn.softmax(tf.matmul(layers_list[-1], self.w_tf_list[-1]) + self.b_tf_list[-1])\n",
    "        \n",
    "        # Loss\n",
    "        cross_entropy = tf.reduce_mean(-tf.reduce_sum(Yph * tf.log(Y_hat), reduction_indices=[1]))\n",
    "        \n",
    "        # accuracy\n",
    "        correct_prediction = tf.equal(tf.argmax(Y_hat, 1), tf.argmax(Yph, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "        # training\n",
    "        train_step = tf.train.GradientDescentOptimizer(self._learning_rate).minimize(cross_entropy)\n",
    "        \n",
    "        #some GPU configuration\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "        config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "        config.gpu_options.allow_growth=True\n",
    "        with tf.Session(config=config) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            pre_acc = 0\n",
    "            for step in range(self._epoches):\n",
    "                #For each step\n",
    "                for start, end in zip(range(0, len(self._X), self._batchsize), range(self._batchsize, len(self._X), self._batchsize)):\n",
    "                    \n",
    "                    sess.run(train_step, feed_dict={Xph: self._X[start:end], Yph: self._Y[start:end]})\n",
    "                print(\"Accuracy at epoch {}: Train={:.4f}, Test={:.4f}\"\n",
    "                      .format(step+1, \n",
    "                              sess.run(accuracy, feed_dict={Xph: mnist.train.images, Yph: mnist.train.labels}), \n",
    "                              sess.run(accuracy, feed_dict={Xph: mnist.test.images, Yph: mnist.test.labels})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(1)\n",
    "layers_size = [500, 200, 50]\n",
    "nNet = FCNN(layers_size, trX, trY, epoches=70)\n",
    "nNet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
